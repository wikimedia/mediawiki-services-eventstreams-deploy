{
  "name": "kafka-sse",
  "version": "0.0.2",
  "description": "KafkaSSE - Kafka Consumer to HTTP SSE/EventSource",
  "main": "index.js",
  "scripts": {
    "start": "./server.js | ./node_modules/bunyan/bin/bunyan",
    "test": "npm run test-jenkins",
    "kafka-install": "./test/utils/kafka_install.sh",
    "kafka-start": "./test/utils/kafka.sh start",
    "kafka-stop": "./test/utils/kafka.sh stop",
    "kafka-fixture": "./test/utils/kafka_fixture.sh",
    "mocha": "export UV_THREADPOOL_SIZE=128; mocha",
    "coverage": "export UV_THREADPOOL_SIZE=128 && ./node_modules/istanbul/lib/cli.js cover _mocha -- -R spec",
    "coveralls": "cat ./coverage/lcov.info | ./node_modules/coveralls/bin/coveralls.js",
    "test-local": "npm run kafka-fixture && npm run coverage",
    "test-jenkins": "npm run kafka-install && npm run kafka-stop && npm run kafka-start && npm run kafka-fixture && npm run coverage && npm run kafka-stop",
    "test-travis": "npm run kafka-install && npm run kafka-start && npm run kafka-fixture && npm run coverage && npm run coveralls"
  },
  "repository": {
    "type": "git",
    "url": "https://phabricator.wikimedia.org/diffusion/WKSK/kasocki.git"
  },
  "keywords": [
    "kafka",
    "http",
    "sse",
    "eventsource",
    "stream"
  ],
  "author": {
    "name": "Andrew Otto",
    "email": "otto@wikimedia.org"
  },
  "license": "Apache-2.0",
  "bugs": {
    "url": "https://phabricator.wikimedia.org/search/query/fpxAPkMeWqjh/"
  },
  "homepage": "https://github.com/ottomata/KafkaSSE#readme",
  "dependencies": {
    "bunyan": "^1.8.1",
    "bluebird": "^3.4.3",
    "node-rdkafka": "git+https://github.com/Blizzard/node-rdkafka.git",
    "lodash": "^4.15.0",
    "safe-regex": "^1.1.0",
    "sse": "^0.0.6",
    "node-uuid": "^1.4.7"
  },
  "devDependencies": {
    "istanbul": "^0.4.4",
    "jscs": "^3.0.7",
    "mocha": "^2.5.3",
    "mocha-jscs": "^5.0.1",
    "mocha-jshint": "^2.3.1",
    "coveralls": "^2.11.11",
    "mocha-lcov-reporter": "^1.2.0",
    "nsp": "^2.6.1",
    "eventsource": "^0.2.1",
    "node-fetch": "^1.6.3",
    "sinon": "^1.17.6"
  },
  "gitHead": "2e2b185db5eac779cda2b88a2e912eb84b860e0e",
  "readme": "# KafkaSSE\n\n[![Travis Build Status](https://travis-ci.org/wikimedia/KafkaSSE.svg?branch=master)](https://travis-ci.org/wikimedia/KafkaSSE)\n[![Coveralls](https://coveralls.io/repos/github/wikimedia/KafkaSSE/badge.svg?branch=master)](https://coveralls.io/github/wikimedia/KafkaSSE?branch=master)\n\nKafka Consumer to HTTP SSE/EventSource\n\nUses [node-rdkafka](https://github.com/Blizzard/node-rdkafka) KafkaConsumer to\nstream JSON messages to clients over HTTP in [SSE/EventSource format](https://www.w3.org/TR/eventsource/)\n\nThe `Last-Event-ID` and EventSource `id` field will be used to handle auto-resume\nduring client disconnects.  By using EventSource to connect to a KafkaSSE endpoint,\nyour client will automatically resume from where it left off if it gets disconnected\nfrom the server.  Every message sent to the client will have an `id` field that will be\na JSON array of objects describing each latest topic, partition and offset seen by this client.\nOn a reconnect, this object will be sent back as the `Last-Event-ID` header, and will be used\nby KafkaSSE to assign a KafkaConsumer to start from those offsets.\n\nSee also [Kasocki](https://github.com/wikimedia/kasocki).\n\n## Usage\n\n### HTTP server KafkaSSE set up\nThe kafka-sse module exports a function that wraps up handling an HTTP SSE request for Kafka topics.\n\n```javascript\n'use strict';\nconst kafkaSse = require('kafka-sse');\nconst server = require('http').createServer();\n\nconst options = {\n    kafkaConfig: {'metadata.broker.list': 'mybroker:9092'}\n}\n\nserver.on('request', (req, res) => {\n    const topics = req.url.replace('/', '').split(',');\n    console.log(`Handling SSE request for topics ${topics}`);\n    kafkaSse(req, res, topics, options)\n    // This won't happen unless client disconnects or kafkaSse encounters an error.\n    .then(() => {\n        console.log('Finished handling SSE request.');\n    });\n});\n\nserver.listen(6917);\nconsole.log('Listening for SSE connections at http:/localhost:6917/:topics');\n```\n\n### NodeJS EventSource usage\n```javascript\nconst EventSource = require('eventsource');\n'use strict';\nconst topics = process.argv[2];\nconst port   = 6917\n\nconst url = `http://localhost:${port}/${topics}`;\nconsole.log(`Connecting to Kafka SSE server at ${url}`);\nlet eventSource = new EventSource(url);\n\neventSource.onopen = function(event) {\n    console.log('--- Opened SSE connection.');\n};\n\neventSource.onerror = function(event) {\n    console.log('--- Got SSE error', event);\n};\n\neventSource.onmessage = function(event) {\n    // event.data will be a JSON string containing the message event.\n    console.log(JSON.parse(event.data));\n};\n```\n\n\n## Errors\n\nIf an error is encountered during SSE client connection, a normal HTTP error response\nwill be returnred, along with JSON information about the error in the response body.\nHowever, once the SSE connection has started, the HTTP response header will have already\nbeen set to 200.  From that point on, errors are given to the client as `onerror` EventSource\nevents.  You must register an `onerror` function for your EventSource object to receive these.\n\n\n## Notes on Kafka consumer state\n\nIn normal use cases, Kafka (and previously Zookeeper) handles consumer state.\nKafka keeps track of multiple consumer processes in named consumer groups, and\nhandles rebalancing of those processes as they come and go.  Kafka also\nhandles offset commits, keeping track of the high water mark each consumer\nhas reached in each topic and partition.\n\nKafkaSSE is intended to be exposed to the public internet by enabling\nweb based consumers to use HTTP to consume from Kafka.  Since\nthe internet at large cannot be trusted, we would prefer to avoid allowing\nthe internet to make any state changes to our Kafka clusters.  KakfaSSE\npushes as much consumer state management to the connected clients as it can.\n\nOffset commits are not supported.  Instead, latest subscription state is sent\nas the EventSource `id` field with each event.  This information can be\nused during connection initializion in the `Last-Event-ID` header\nto specify the positions at which KafkaSSE should start consuming from Kafka.\n`Last-Event-ID` should be an assignments array, of the form:\n\n```javascript\n[\n    { topic: 'topicA', partition: 0, offset 12345 },\n    { topic: 'topicB', partition: 0, offset 46666 },\n    { topic: 'topicB', partition: 1, offset 45555 },\n]\n```\n\nConsumer group management is also not supported.  Each new SSE client\ncorresponds to a new consumer group.  There is no way to parallelize\nconsumption from Kafka for a single connected client.  Ideally, we would not\nregister a consumer group at all with Kafka, but as of this writing\n[librdkafka](https://github.com/Blizzard/node-rdkafka/issues/18) and\n[blizzard/node-rdkafka](https://github.com/Blizzard/node-rdkafka/issues/18)\ndon't support this yet.  Consumer groups that are registered with Kafka\nare named after the `x-request-id` header, or a uuid if this is not set, e.g.\n`KafkaSSE-2a360ded-1da0-4258-bad5-90ce954b7c52`.\n\n## node-rdkafka consume modes\nThe node-rdkafka client that KafkaSSE uses has\n[several consume APIs](https://github.com/Blizzard/node-rdkafka#kafkakafkaconsumer).\nKafkaSSE uses the [Standard Non flowing API](https://github.com/Blizzard/node-rdkafka#standard-api-1).\n\n\n## Testing\nMocha tests require a running 0.9+ Kafka broker at `localhost:9092` with\n`delete.topic.enable=true`.  `test/utils/kafka_fixture.sh` will prepare\ntopics in Kafka for tests.  `npm test` will download, install, and run\na Kafka broker.  If you already have one running locally, then\n`npm run test-local` will be easier to run.\n\nNote that there is a\n[bug in librdkafka/node-rdkafka](https://github.com/edenhill/librdkafka/issues/775)\nthat keeps tests from shutting down once done.  This bug also has implications\nfor the number of consumers a process can run at once in its lifetime,\nand will have to be resolved somehow before this is put into production.\n\n\n## To Do\n\n- tests for kafkaEventHandlers\n- statsd + metrics\n- Get upstream fix for https://github.com/Blizzard/node-rdkafka/issues/5\n  this will need to be resolved before this can be used in any type of production\n  setting.\n- rdkafka statsd: https://phabricator.wikimedia.org/T145099\n- filter, jsonschema? jsonschema query?\n\n- Replace Kasocki references in package.json",
  "readmeFilename": "README.md",
  "_id": "kafka-sse@0.0.2",
  "_shasum": "2bcda1b5dc07ec6057d307bf8f07421c8b4d2de1",
  "_from": "git+https://phabricator.wikimedia.org/diffusion/WKSE/kafkasse.git",
  "_resolved": "git+https://phabricator.wikimedia.org/diffusion/WKSE/kafkasse.git#2e2b185db5eac779cda2b88a2e912eb84b860e0e"
}
